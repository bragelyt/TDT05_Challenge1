{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impementation of Catboost\n",
    "\n",
    "To solve this problem I descided on using CatBoost Classifier. CatBoost is a decision tree clasifier that accells on categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata and parameters\n",
    "\n",
    "For the model to be able to distinguish between continous, number valriables and categorical values a list of string varibles, as well as some \"categorical-looking\" variables are passed in to a list. More on this choice in the other notebook.\n",
    "\n",
    "After importing the dataset all nan values are sett to -1, a value not used in the dataset, here used to make a new category representing NaN values for the model. Afther that the dataset is split into X and Y sets, or variable and target sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalVars = [0, 1, 5, 7, 9, 11, 12, 14, 15, 23, 24, 27, 2, 3, 13, 18, 20, 26]\n",
    "learningRate = 0.01\n",
    "\n",
    "addHexVars = False\n",
    "addIntCategorcalVars = False\n",
    "iterations = 2500\n",
    "depth = 11\n",
    "seed = 1\n",
    "evalSize = 0.15\n",
    "\n",
    "dataTrain = pd.read_csv(\"data/challenge1_train.csv\")\n",
    "\n",
    "noNans = dataTrain.fillna(0)\n",
    "\n",
    "values = noNans.values\n",
    "X = values[:,2:31]\n",
    "Y = values[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical int vars\n",
    "\n",
    "This is togglable method if one wants to use some of the number variables as categories. To do this the variables must be converted to int to be accepted by CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intVars = [6, 8, 22, 28]\n",
    "\n",
    "if addIntCategorcalVars:\n",
    "    for col in intVars:\n",
    "        categoricalVars.append(col)\n",
    "        for i, item in enumerate(X[:,col]):\n",
    "            X[:,col][i] = int(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hex vars\n",
    "\n",
    "This is a togglable method to convert hexadecimal values to decimal numbers and make them continous variables, not categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexVars = [2, 3, 13, 18, 20, 26]\n",
    "\n",
    "if addHexVars:\n",
    "    for col in hexVars:\n",
    "        categoricalVars.remove(col)\n",
    "        for i, item in enumerate(X[:,col]):\n",
    "            if \"E+\" in str(item):\n",
    "                item = int(float(str(item)))\n",
    "            X[:,col][i] = int(str(item), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiaing the model\n",
    "\n",
    "Parameters are passed in to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations = iterations,\n",
    "    depth = depth,\n",
    "    learning_rate=learningRate,\n",
    "    eval_metric=\"AUC\",\n",
    "    early_stopping_rounds=100,\n",
    "    loss_function='Logloss',\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'train_test_split' and 'fit'\n",
    "\n",
    "'train_test_split' splits data into two sets, one for training and fitting the model and one for evaluation. \n",
    "For highest score this should be ignored and X and Y should be passed in to 'model.fit' in place of xTrain and yTrain. \n",
    "Though there is a risk of overfitting this results in a moddel trained on the most data giving the highest score in this (or in my) case. \n",
    "To be able to display a nice graph with estimation of score a eval_set that is not contained within the training set should be passed in to 'model.fit'\n",
    "'train_test_split' was valuable during the tunig phase as one could get a good estimate of the accuracy of the model without submitting an atempt.\n",
    "\n",
    "'model.fit' uses 'logloss' to minimize the difference between estimation and target in the trainingset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d390289d441491b818f42885c667afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 46.6ms\tremaining: 2m 19s\n",
      "100:\ttotal: 24.5s\tremaining: 11m 43s\n",
      "200:\ttotal: 55.4s\tremaining: 12m 50s\n",
      "300:\ttotal: 1m 29s\tremaining: 13m 20s\n",
      "400:\ttotal: 2m 3s\tremaining: 13m 19s\n",
      "500:\ttotal: 2m 37s\tremaining: 13m 5s\n",
      "600:\ttotal: 3m 12s\tremaining: 12m 47s\n",
      "700:\ttotal: 3m 47s\tremaining: 12m 26s\n",
      "800:\ttotal: 4m 22s\tremaining: 12m 1s\n",
      "900:\ttotal: 5m\tremaining: 11m 39s\n",
      "1000:\ttotal: 5m 36s\tremaining: 11m 11s\n",
      "1100:\ttotal: 6m 12s\tremaining: 10m 43s\n",
      "1200:\ttotal: 6m 49s\tremaining: 10m 13s\n",
      "1300:\ttotal: 7m 26s\tremaining: 9m 42s\n",
      "1400:\ttotal: 8m 3s\tremaining: 9m 11s\n",
      "1500:\ttotal: 8m 40s\tremaining: 8m 39s\n",
      "1600:\ttotal: 9m 18s\tremaining: 8m 8s\n",
      "1700:\ttotal: 9m 57s\tremaining: 7m 36s\n",
      "1800:\ttotal: 10m 36s\tremaining: 7m 3s\n",
      "1900:\ttotal: 11m 18s\tremaining: 6m 32s\n",
      "2000:\ttotal: 12m 1s\tremaining: 6m\n",
      "2100:\ttotal: 12m 42s\tremaining: 5m 26s\n",
      "2200:\ttotal: 13m 23s\tremaining: 4m 51s\n",
      "2300:\ttotal: 14m 4s\tremaining: 4m 16s\n",
      "2400:\ttotal: 14m 45s\tremaining: 3m 40s\n",
      "2500:\ttotal: 15m 27s\tremaining: 3m 5s\n",
      "2600:\ttotal: 16m 9s\tremaining: 2m 28s\n",
      "2700:\ttotal: 16m 51s\tremaining: 1m 51s\n",
      "2800:\ttotal: 17m 34s\tremaining: 1m 14s\n",
      "2900:\ttotal: 18m 16s\tremaining: 37.4s\n",
      "2999:\ttotal: 18m 58s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x165278890d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=evalSize, random_state=seed)\n",
    "model.fit(X, Y, cat_features=categoricalVars, plot = True)\n",
    "# model.fit(xTrain, yTrain, cat_features=categoricalVars, eval_set=(xTest, yTest), plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test data set\n",
    "\n",
    "Before we can use the model to make predictions on the test set we need to apply the same opperations to the train set as we have done to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"data/challenge1_test.csv\").fillna(0)\n",
    "testData.drop(columns=testData.columns[0], axis=1, inplace=True)\n",
    "testData = testData.values\n",
    "\n",
    "if addIntCategorcalVars:\n",
    "    for col in intVars:\n",
    "        for i, item in enumerate(testData[:,col]):\n",
    "            testData[:,col][i] = int(item)\n",
    "\n",
    "if addHexVars:\n",
    "    for col in hexVars:\n",
    "        for i, item in enumerate(testData[:,col]):\n",
    "            if \"E+\" in str(item):\n",
    "                item = int(float(str(item)))\n",
    "            testData[:,col][i] = int(str(item), 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Predictions made by the model is passed out as a probability distribution of the different classes the model are classifying (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76937343, 0.23062657],\n",
       "       [0.86605208, 0.13394792],\n",
       "       [0.88376238, 0.11623762],\n",
       "       ...,\n",
       "       [0.91861852, 0.08138148],\n",
       "       [0.88467169, 0.11532831],\n",
       "       [0.91020712, 0.08979288]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_proba(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to file\n",
    "\n",
    "Finaly the prediction (probability of the output being a 1) is written to a csv file along with the id of the row the prediction is made on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\"id\": [], \"target\": []}\n",
    "for i, prediction in enumerate(predictions):\n",
    "    out[\"id\"].append(i+50000)\n",
    "    out[\"target\"].append(prediction[1])\n",
    "df = pd.DataFrame(out) \n",
    "df.to_csv('Predictions.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4a4e8c0e9e6bfd3d095881ad47ec74045d82e6a66e0ece2d21872c41ff48211"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
