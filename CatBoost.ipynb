{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impementation of Catboost\n",
    "\n",
    "To solve this problem I descided on using CatBoost Classifier. CatBoost is a decision tree clasifier that accells on categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata and parameters\n",
    "\n",
    "For the model to be able to distinguish between continous, number valriables and categorical values a list of string varibles, as well as some \"categorical-looking\" variables are passed in to a list. More on this choice in the other notebook.\n",
    "\n",
    "After importing the dataset all nan values are sett to -1, a value not used in the dataset, here used to make a new category representing NaN values for the model. Afther that the dataset is split into X and Y sets, or variable and target sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalVars = [0, 1, 5, 7, 9, 11, 12, 14, 15, 23, 24, 27, 2, 3, 13, 18, 20, 26]\n",
    "learningRate = 0.01\n",
    "\n",
    "addHexVars = False\n",
    "addIntCategorcalVars = False\n",
    "iterations = 3500\n",
    "depth = 11\n",
    "seed = 1\n",
    "evalSize = 0.15\n",
    "\n",
    "dataTrain = pd.read_csv(\"data/challenge1_train.csv\")\n",
    "\n",
    "noNans = dataTrain.fillna(0)\n",
    "\n",
    "values = noNans.values\n",
    "X = values[:,2:31]\n",
    "Y = values[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical int vars\n",
    "\n",
    "This is togglable method if one wants to use some of the number variables as categories. To do this the variables must be converted to int to be accepted by CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "intVars = [6, 8, 22, 28]\n",
    "\n",
    "if addIntCategorcalVars:\n",
    "    for col in intVars:\n",
    "        categoricalVars.append(col)\n",
    "        for i, item in enumerate(X[:,col]):\n",
    "            X[:,col][i] = int(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hex vars\n",
    "\n",
    "This is a togglable method to convert hexadecimal values to decimal numbers and make them continous variables, not categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexVars = [2, 3, 13, 18, 20, 26]\n",
    "\n",
    "if addHexVars:\n",
    "    for col in hexVars:\n",
    "        categoricalVars.remove(col)\n",
    "        for i, item in enumerate(X[:,col]):\n",
    "            if \"E+\" in str(item):\n",
    "                item = int(float(str(item)))\n",
    "            X[:,col][i] = int(str(item), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiaing the model\n",
    "\n",
    "Parameters are passed in to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations = iterations,\n",
    "    depth = depth,\n",
    "    learning_rate=learningRate,\n",
    "    eval_metric=\"AUC\",\n",
    "    early_stopping_rounds=100,\n",
    "    loss_function='Logloss',\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'train_test_split' and 'fit'\n",
    "\n",
    "'train_test_split' splits data into two sets, one for training and fitting the model and one for evaluation. \n",
    "For highest score this should be ignored and X and Y should be passed in to 'model.fit' in place of xTrain and yTrain. \n",
    "Though there is a risk of overfitting this results in a moddel trained on the most data giving the highest score in this (or in my) case. \n",
    "To be able to display a nice graph with estimation of score a eval_set that is not contained within the training set should be passed in to 'model.fit'\n",
    "\n",
    "'model.fit' uses 'logloss' to minimize the difference between estimation and target in the trainingset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf37d7a6e442268f5b294f172197b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 236ms\tremaining: 8m 51s\n",
      "100:\ttotal: 1m 43s\tremaining: 36m 34s\n",
      "200:\ttotal: 3m 51s\tremaining: 39m 22s\n",
      "300:\ttotal: 5m 58s\tremaining: 38m 43s\n",
      "400:\ttotal: 8m 11s\tremaining: 37m 46s\n",
      "500:\ttotal: 10m 10s\tremaining: 35m 30s\n",
      "600:\ttotal: 12m 6s\tremaining: 33m 12s\n",
      "700:\ttotal: 14m 1s\tremaining: 31m\n",
      "800:\ttotal: 15m 54s\tremaining: 28m 46s\n",
      "900:\ttotal: 18m 5s\tremaining: 27m 4s\n",
      "1000:\ttotal: 20m 9s\tremaining: 25m 9s\n",
      "1100:\ttotal: 22m 35s\tremaining: 23m 34s\n",
      "1200:\ttotal: 24m 51s\tremaining: 21m 42s\n",
      "1300:\ttotal: 27m 21s\tremaining: 19m 57s\n",
      "1400:\ttotal: 29m 43s\tremaining: 18m\n",
      "1500:\ttotal: 31m 48s\tremaining: 15m 52s\n",
      "1600:\ttotal: 34m 26s\tremaining: 13m 57s\n",
      "1700:\ttotal: 37m 6s\tremaining: 11m 58s\n",
      "1800:\ttotal: 39m 38s\tremaining: 9m 52s\n",
      "1900:\ttotal: 42m 20s\tremaining: 7m 46s\n",
      "2000:\ttotal: 45m 26s\tremaining: 5m 39s\n",
      "2100:\ttotal: 48m 4s\tremaining: 3m 24s\n",
      "2200:\ttotal: 50m 34s\tremaining: 1m 7s\n",
      "2249:\ttotal: 51m 46s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2507b5b5e80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=evalSize, random_state=seed)\n",
    "model.fit(X, Y, cat_features=categoricalVars, plot = True)\n",
    "# model.fit(xTrain, yTrain, cat_features=categoricalVars, eval_set=(xTest, yTest), plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test data set\n",
    "\n",
    "Before we can use the model to make predictions on the test set we need to apply the same opperations to the train set as we have done to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"data/challenge1_test.csv\").fillna(0)\n",
    "testData.drop(columns=testData.columns[0], axis=1, inplace=True)\n",
    "testData = testData.values\n",
    "\n",
    "if addIntCategorcalVars:\n",
    "    for col in intVars:\n",
    "        for i, item in enumerate(testData[:,col]):\n",
    "            testData[:,col][i] = int(item)\n",
    "\n",
    "if addHexVars:\n",
    "    for col in hexVars:\n",
    "        for i, item in enumerate(testData[:,col]):\n",
    "            if \"E+\" in str(item):\n",
    "                item = int(float(str(item)))\n",
    "            testData[:,col][i] = int(str(item), 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Predictions made by the model is passed out as a probability distribution of the different classes the model are classifying (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72897541, 0.27102459],\n",
       "       [0.88920728, 0.11079272],\n",
       "       [0.87677329, 0.12322671],\n",
       "       ...,\n",
       "       [0.92184236, 0.07815764],\n",
       "       [0.87759518, 0.12240482],\n",
       "       [0.9183203 , 0.0816797 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_proba(testData)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to file\n",
    "\n",
    "Finaly the prediction (probability of the output being a 1) is written to a csv file along with the id of the row the prediction is made on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\"id\": [], \"target\": []}\n",
    "for i, prediction in enumerate(predictions):\n",
    "    out[\"id\"].append(i+50000)\n",
    "    out[\"target\"].append(prediction[1])\n",
    "df = pd.DataFrame(out) \n",
    "df.to_csv('Predictions.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "881bb3b54a64582659086eab605df57fb5ff1007581fc607c44d3359ff5b16da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
